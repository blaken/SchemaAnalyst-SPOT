\documentclass[a4paper,twocolumn]{article}

\usepackage{cite}
\usepackage[utf8x]{inputenc}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[colorinlistoftodos]{todonotes}

\title{Optimizing SchemaAnalyst Parameter Usage with \texttt{SPOT}}
\author{Nathaniel Blake \\ \textit{Department of Computer Science} \\ \textit{Allegheny College} \and Colin Soleim \\ \textit{Department of Computer Science} \\ \textit{Allegheny College}}
\date{}

\begin{document}

\maketitle

\section{Introduction}

The parameters of a system can play a large role in every aspect of its performance, but they are often set or changed based only on loose testing. Parameter optimization is an attempt to create an experiment to look through a more complete list of possible configurations and accordingly tune a system. The method of sequential parameter optimization has been a popular framework to use since its introduction by Bartz-Beielstein in 2006. Shortly after his initial paper was published, he followed up with a package for R known as the Sequential Parameter Optimization Toolbox or SPOT. This can be found on the Complete R Archive Network website at http://cran.r-project.org/web/packages/SPOT/index.html. 

Our experiment uses this R package to test the parameters of a new search-based testing system for relational schemas created by Kapfhammer, McMinn, and Wright known as SchemaAnalyst. This tool first takes in a database schema and converts it into a universal representation. Then, for each integrity constraint within the schema, SchemaAnalyst attempts to create one SQL INSERT statement to satisfy the constraint and one to negate the constraint. For each type of constraint, SchemaAnalyst calculates a distance metric based on how close a constraint is to being satisfied. This is used as the fitness function which is then minimized using the Alternating Variable Method. 

With the data generated, mutation analysis is performed to test the effectiveness of the data. Mutants are generated for each specific class of integrity constraint. This mutation analysis was our primary metric for testing the performance of different configurations of SchemaAnalyst. We created configurations for SchemaAnalyst based on four key parameters in SchemaAnalyst: satisfyrows, negaterows, randomprofile, and randomseed.

The results of our experiment give definitive evidence that SchemaAnalyst mutation scores can be optimized by configuring parameters using SPOT. In all 8 schemas tested, our optimized configurations outperform the defaults that SchemaAnalyst currently uses. We show that by far the most important parameter is satisfyrows, with randomseed, negaterows, and randomprofile having second, third, and fourth priority respectively across all schemas tested. With this conclusive proof that our technique is effective, we will run a full suite of tests on the 44 schemas available in the repository to find results that apply generally to either all schemas or broad classes of schemas. 

The current empirical study that we have completed contributes:

\begin{enumerate}
\item a set of regression trees indicating what configuration settings are best for each schema,
\item evidence that parameters optimized by SPOT perform better than the default configurations of SchemaAnalyst,
\item an ordering of parameters by their importance in mutation analysis score.
\end{enumerate}

\section{SPOT} \label{sec:SPOT}

TODO: Description of how SPOT works

\section{SchemaAnalyst} \label{sec:schemaanalyst}

TODO: Full Description of how SchemaAnalyst works. QUESTION: How long should this section be? How much of the detail from the ICST paper would be appropriate for this new paper? 

\section{Description of Experiment Design} \label{sec:exp-des}

The core experiment in our research follows the standard use model for SchemaAnalyst, beginning with $(1)$ generation of a set $D$ of database interactions that either satisfy or negate a provided schema $S$ and then $(2)$ running mutation analysis in which the interactions in $D$ are used to try to kill a series of mutant schemas, $S'_1, \dots, S'_n$.

In particular, our \texttt{experiment.R} code uses \texttt{SPOT} to generate parameter designs that include the following four parameters:
\begin{enumerate}
\item \texttt{satisfyrows}, the number of database interactions that satisfy the original schema's constraints,
\item \texttt{negaterows}, the number of database interactions that violate the original schema's constraints in at least one way,
\item \texttt{randomprofile}, a value of either \texttt{'large'} or \texttt{'small'} that determines the scope considered during AVM restarts, and
\item \texttt{randomseed}, a number used to seed the AVM's decisions when using random restart, as well as the seed to the \texttt{Random} generator.
\end{enumerate}

There are two important additional parameters to the generation phase that are not included in our usage of SPOT. The first, \texttt{datagenerator}, is specified by the user at the time of experiment configuration and determines the generator that is used for the entirety of the experiment run's evaluations. The other, \texttt{maxevaluations}, is statically set to an arbitrarily high value of $1,000,000$, since low values are sure to prevent the experiment from producing useful results (because generation will be terminated before the requested number of statements has been created) but higher values are only better to the extent that they do not prevent generation from terminating unnecessarily.

Once \texttt{SPOT} has created a parameter configuration, SchemaAnalyst's \texttt{GenerateResultsFromGenerator} is executed with the provided parameters, and its execution time is measured as a secondary optimization target for \texttt{SPOT}. Once generation is complete, SchemaAnalyst's \texttt{Original} mutation analysis is used against the generated database interactions; \texttt{Original} was chosen because it provides the most comprehensive coverage of mutant types among available techniques, even though it is not as well optimized as others. Following mutation analysis, the mutation score is recorded, and its inverse is provided to \texttt{SPOT} as the primary optimization target (we use its inverse, calculated as $1 - \frac{\text{Killed Mutants}}{\text{Total Mutants}}$ since \texttt{SPOT} always optimizes using minimization).

From here, \texttt{SPOT} proceeds as described in Section~\ref{sec:SPOT} and in \cite{SPOT2005}, calculating the relative importance of each of the parameters using \texttt{RandomForest} prediction and optimizing its design accordingly over a number of evaluations defined during experiment configuration, storing the mutation score and generation time for each of the configurations that it has tried for later analysis.

\section{Preliminary Analysis of Results}

In our first round of comprehensive data collection and analysis, we ran our experiment with $8$ different schemas of varying complexity (listed in~\nameref{appA}), for each using both \texttt{alternatingValue} and \texttt{alternatingValueDefaults} generators. Before proceeding to analysis, we removed result sets in which every parameter configuration resulted in a mutation score of $1$---at the time being, these data sets obstruct the function of our analysis tools (the use of \texttt{RandomForest}, in particular).

%TODO add citation to compute.es documentation to show how effect size is calculated here
The most general measure of the result sets is the \textit{effect size}, a measure of the strength of the relationship between the mutation scores generated using default parameter values and those generated using optimal parameter configurations determined by \texttt{SPOT} experimentation. For our set of $12$ result sets, the computed Cohen's $d$ value is $0.76$, indicating that there is a relatively strong positive correlation between using optimized parameter values and getting a higher mutation score.

\begin{figure}[t]
\begin{center}
%TODO generate graphics specifically for use in the LaTeX document that are easier to see, sans title
\includegraphics[width=0.90\columnwidth]{mutation-score-importance.pdf}
\caption{Parameter importance on mutation score}
\end{center}
\label{fig:mut-param-imp}
\end{figure}

A similarly broad analysis measures the relative importance of each parameter that is being optimized (refer to~\nameref{sec:exp-des} for parameter descriptions) relative to one of the optimization targets. For instance, Figure~\ref{fig:mut-param-imp} shows that \texttt{SatisfyRows} has the greatest effect on the mutation score, with \texttt{RandomSeed} placing as next most important. This result is reasonable, since a larger number of satisfying database interactions would tailor the set of statements $D$ more closely to the original schema $S$. Then, when $S$ is mutated to form $S'$, at least one of the statements well-suited to $S$ is likely not to be well-suited to $S'$, especially in the case when complex constraints are modified to form $S'$. Likewise, the minimal importance of $NegateRows$ follows since statements that violate $S$ would require that the precise constraint(s) that they violate be modified in the formation of $S'$; this is unlikely, so having a large number of negating interactions is unhelpful to killing mutant schemas, since they're unlikely to be accepted by any schema related to $S$.

%TODO add similar analysis to above for generation-time-importance.pdf

\begin{figure}[t]
\begin{center}
%TODO generate graphics specifically for use in the LaTeX document that are easier to see, sans title
\includegraphics[width=0.90\columnwidth]{NistDML183-regressiontree.pdf}
\caption{Regression tree for NistDML183}
\end{center}
\label{fig:CART}
\end{figure}

We can apply these broad results to analysis of a single result set as well. We see in Figure~\ref{fig:CART} that the first two branches of the classification tree depend on the value of \texttt{SatisfyRows}, again indicative of its correlation to the resultant mutation score; in this case, setting \texttt{SatisfyRows} to $9$ or greater is likely to ensure that the mutation score is near its optimal value in this result set.


\bibliographystyle{acm}
\bibliography{references}

\pagebreak

\section*{Appendix A} \label{appA}
\textit{Listing of schemas tested for preliminary analysis}
\begin{itemize}
\item \texttt{Flights}
\item \texttt{JWhoisServer}
\item \texttt{NistDML181}
\item \texttt{NistDML181NotNulls}
\item \texttt{NistDML182}
\item \texttt{NistDML182NotNulls}
\item \texttt{NistDML183}
\item \texttt{UnixUsage}
\end{itemize}

\end{document}


